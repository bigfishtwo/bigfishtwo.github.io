---
title: nnUNet 论文以及代码解析
date: 2024-01-02 +0800
categories: [论文笔记]
tags: [医学图像,分割]
---

nnUNet 论文： 

[nnU-Net: Self-adapting Framework for U-Net-Based Medical Image Segmentation](https://arxiv.org/pdf/1809.10486.pdf)

nnU-Net: a self-configuring method for deep learning-based biomedical image segmentation

代码：https://github.com/MIC-DKFZ/nnUNet

我会分成两部来写，上半部分是nnUNet论文里的内容，下半部分是nnUNet框架的使用。

在医学图像分割领域， nnUNet 总是一个绕不开的名字，每个新提出来的分割方法都要和 nnUNet 做对比，在某一个数据集上超越了 nnUNet，却在另一个不同的数据集上被 nnUNet 吊打，可以说到目前为止 nnUNet 依旧是医学图像分割的首选。

![20240102225204](https://cdn.jsdelivr.net/gh/bigfishtwo/BlogPics@main/imgs/20240102225204.png)
_不同模型在 TotalSegmentator 数据集上的表现，结果来自STU-Net论文[1]_

那么什么是 nnUNet ？nnUNet 是no-new-Net的缩写，指的是基于 2D 和 3D vanilla U-Nets 的鲁棒自适应框架。作者并没有加入一些花里胡哨的技巧，只是做了一些小改动，比如 ReLU 改成 Leaky ReLU 之类的。作者认为，与架构变化相比，方法配置的细节对性能的影响更大。

nnUNet 提出了一个可以自动配置的 pipline，包括了预处理、网络架构、训练和后处理，能够适应任何新的医学数据集。下面就介绍 nnUNet 的具体设置。

## 1. nnU-Net 的开发

nnU-Net 的自动配置基于将领域知识提炼为三个参数组：**固定参数、基于规则的参数和经验参数**。

首先，作者列出所有不需要在数据集之间进行调整的设计选择（例如将架构模板设置为 "类 U-Net"），并优化它们的联合配置，以便在开发数据集上实现稳健的泛化。

其次，对于尽可能多的剩余决策，作者在 "数据集指纹 "和 "管道指纹 "之间建立了明确的依赖关系。"数据集指纹 "是一种标准化的数据集表示法，包含图像大小、体素间距信息或类比等关键属性。依赖关系以相互依存的启发式规则形式建模，在应用时几乎可以立即执行。举例来说，批量大小、补丁大小和网络拓扑结构的相互依存配置基于以下三个原则：

- **较大的 batch size**可以获得更准确的梯度估计，因此是可取的（在作者的领域中通常达不到最佳规模），但在实践中，任何大于 1 的 batch 都会影响训练的鲁棒性。
- 在训练过程中，**较大的 patch size** 会增加网络吸收的上下文信息，因此对性能至关重要。
- 网络的拓扑结构应该**足够深**，以保证有效感受野的大小至少与 patch 大小一样大，这样才不会丢弃上下文信息。

将这些知识提炼到成功的方法设计中，就形成了以下启发式规则：

"将补丁大小初始化为图像形状中值，然后迭代减小补丁大小，同时相应调整网络拓扑结构（包括网络深度、沿每个轴进行池化操作的次数和位置、特征图大小和卷积核大小），直到在 GPU 内存限制的情况下，网络的批量大小至少可以达到两个"。





参考：
- [1] STU-Net: Scalable and Transferable Medical Image Segmentation Models Empowered by Large-Scale Supervised Pre-training